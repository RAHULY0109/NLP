{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b458b265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Loading dataset...\n",
      "[info] Using kagglehub to download dataset...\n",
      "[info] kagglehub path: C:\\Users\\jaypr\\.cache\\kagglehub\\datasets\\uciml\\sms-spam-collection-dataset\\versions\\1\n",
      "[info] Loading: C:\\Users\\jaypr\\.cache\\kagglehub\\datasets\\uciml\\sms-spam-collection-dataset\\versions\\1\\spam.csv\n",
      "[info] Dataset size: 5572 (ham=4825, spam=747)\n",
      "\n",
      "[info] Running EDA...\n",
      "[info] Saved wordcloud: artifacts\\wordcloud_ham.png\n",
      "[info] Saved wordcloud: artifacts\\wordcloud_spam.png\n",
      "\n",
      "[info] Data split:\n",
      "  Train size: 4457  Test size: 1115\n",
      "\n",
      "=== BoW + LogisticRegression ===\n",
      "F1-macro: 0.9501\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham     0.9758    1.0000    0.9877       966\n",
      "        spam     1.0000    0.8389    0.9124       149\n",
      "\n",
      "    accuracy                         0.9785      1115\n",
      "   macro avg     0.9879    0.9195    0.9501      1115\n",
      "weighted avg     0.9790    0.9785    0.9777      1115\n",
      "\n",
      "[info] Saved report: artifacts\\classification_report_bow_+_logisticregression.txt\n",
      "\n",
      "=== TF-IDF + LogisticRegression ===\n",
      "F1-macro: 0.9345\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham     0.9698    0.9990    0.9842       966\n",
      "        spam     0.9917    0.7987    0.8848       149\n",
      "\n",
      "    accuracy                         0.9722      1115\n",
      "   macro avg     0.9808    0.8988    0.9345      1115\n",
      "weighted avg     0.9728    0.9722    0.9709      1115\n",
      "\n",
      "[info] Saved report: artifacts\\classification_report_tf-idf_+_logisticregression.txt\n",
      "\n",
      "=== TF-IDF+Preproc + LogisticRegression ===\n",
      "F1-macro: 0.9302\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham     0.9688    0.9979    0.9832       966\n",
      "        spam     0.9833    0.7919    0.8773       149\n",
      "\n",
      "    accuracy                         0.9704      1115\n",
      "   macro avg     0.9761    0.8949    0.9302      1115\n",
      "weighted avg     0.9708    0.9704    0.9690      1115\n",
      "\n",
      "[info] Saved report: artifacts\\classification_report_tf-idf+preproc_+_logisticregression.txt\n",
      "\n",
      "=== Final Scores (same classifier across methods) ===\n",
      "                Method  F1_macro\n",
      "                   BoW  0.950069\n",
      "                TF-IDF  0.934475\n",
      "TF-IDF + Preprocessing  0.930248\n",
      "[info] Saved final scores: artifacts\\final_scores.csv\n",
      "[info] Summary JSON saved at artifacts\\run_summary.json\n"
     ]
    }
   ],
   "source": [
    "# SMS Spam Detection: EDA + BoW + TF-IDF + Preprocessing\n",
    "# -----------------------------------------------------------\n",
    "# This script:\n",
    "# 1) Loads the \"SMS Spam Collection\" dataset via kagglehub\n",
    "# 2) Performs EDA (top words/bigrams/trigrams per class + wordclouds)\n",
    "# 3) Builds a baseline Bag-of-Words + Logistic Regression model\n",
    "# 4) Builds a TF-IDF + Logistic Regression model\n",
    "# 5) Adds text preprocessing (tokenize, lowercase, remove emails/urls/html, numbers, punctuation,\n",
    "#    remove stopwords, lemmatize) + TF-IDF + Logistic Regression\n",
    "# 6) Prints the F1-scores for the three setups and saves artifacts to /mnt/data\n",
    "#\n",
    "# Run:\n",
    "#   python sms_spam_pipeline.py\n",
    "#\n",
    "# Notes:\n",
    "# - The same classifier (LogisticRegression) is used across all three experiments.\n",
    "# - Artifacts (plots and CSVs) are saved into ./artifacts by default.\n",
    "# - If running in Kaggle/Colab, internet should be available for any pip installs (if needed).\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import string\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional installs for environments that may not have these\n",
    "def _ensure_packages():\n",
    "    try:\n",
    "        import nltk  # noqa: F401\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nltk\"])\n",
    "\n",
    "    try:\n",
    "        from wordcloud import WordCloud  # noqa: F401\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"wordcloud\"])\n",
    "\n",
    "    # kagglehub is nice-to-have (we fall back gracefully if missing)\n",
    "    try:\n",
    "        import kagglehub  # noqa: F401\n",
    "    except ImportError:\n",
    "        try:\n",
    "            import subprocess\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"kagglehub\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "_ensure_packages()\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# NLTK downloads (idempotent)\n",
    "def _ensure_nltk_data():\n",
    "    resources = [\n",
    "        (\"punkt\", \"tokenizers/punkt\"),\n",
    "        (\"punkt_tab\", \"tokenizers/punkt_tab\"),  # newer nltk sometimes needs this\n",
    "        (\"stopwords\", \"corpora/stopwords\"),\n",
    "        (\"wordnet\", \"corpora/wordnet\"),\n",
    "        (\"omw-1.4\", \"corpora/omw-1.4\"),\n",
    "        (\"averaged_perceptron_tagger\", \"taggers/averaged_perceptron_tagger\"),\n",
    "        (\"averaged_perceptron_tagger_eng\", \"taggers/averaged_perceptron_tagger_eng\"),  # NLTK 3.8+\n",
    "    ]\n",
    "    for pkg, path in resources:\n",
    "        try:\n",
    "            nltk.data.find(path)\n",
    "        except LookupError:\n",
    "            nltk.download(pkg, quiet=True)\n",
    "\n",
    "_ensure_nltk_data()\n",
    "\n",
    "# ---------------------\n",
    "# Config\n",
    "# ---------------------\n",
    "ARTIFACT_DIR = Path(\"./artifacts\")\n",
    "ARTIFACT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TOPK = 10\n",
    "\n",
    "# ---------------------\n",
    "# Data Loading\n",
    "# ---------------------\n",
    "def load_sms_spam():\n",
    "    \"\"\"\n",
    "    Load the UCI SMS Spam Collection dataset via kagglehub (if available).\n",
    "    Falls back to searching the current directory for a CSV with columns v1 (label) and v2 (text).\n",
    "    Returns a DataFrame with columns: ['label', 'text'].\n",
    "    \"\"\"\n",
    "    path = None\n",
    "    try:\n",
    "        import kagglehub\n",
    "        print(\"[info] Using kagglehub to download dataset...\")\n",
    "        path = kagglehub.dataset_download(\"uciml/sms-spam-collection-dataset\")\n",
    "        print(\"[info] kagglehub path:\", path)\n",
    "        base = Path(path)\n",
    "        # The dataset usually contains 'spam.csv'\n",
    "        candidates = list(base.glob(\"*.csv\"))\n",
    "        if not candidates:\n",
    "            # some mirrors might place the file in nested directories\n",
    "            candidates = list(base.rglob(\"*.csv\"))\n",
    "    except Exception as e:\n",
    "        print(\"[warn] kagglehub unavailable or failed:\", repr(e))\n",
    "        # fallback: search local folder\n",
    "        base = Path(\".\")\n",
    "        candidates = list(base.glob(\"*.csv\")) + list(base.rglob(\"*.csv\"))\n",
    "\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\"Could not find a CSV file for the SMS dataset. \"\n",
    "                                \"Please ensure 'spam.csv' (with columns v1,v2) is present.\")\n",
    "\n",
    "    # prefer a file named spam.csv if present\n",
    "    csv_path = None\n",
    "    for c in candidates:\n",
    "        if c.name.lower() == \"spam.csv\":\n",
    "            csv_path = c\n",
    "            break\n",
    "    if csv_path is None:\n",
    "        csv_path = candidates[0]\n",
    "\n",
    "    print(f\"[info] Loading: {csv_path}\")\n",
    "    # The CSV sometimes uses latin-1\n",
    "    df = pd.read_csv(csv_path, encoding=\"latin-1\")\n",
    "    # Some versions have extra unnamed columns; keep only 'v1','v2'\n",
    "    if \"v1\" in df.columns and \"v2\" in df.columns:\n",
    "        df = df[[\"v1\", \"v2\"]].rename(columns={\"v1\": \"label\", \"v2\": \"text\"})\n",
    "    elif \"label\" in df.columns and \"message\" in df.columns:\n",
    "        df = df[[\"label\", \"message\"]].rename(columns={\"label\": \"label\", \"message\": \"text\"})\n",
    "    else:\n",
    "        # Try to auto-detect the first two columns\n",
    "        df = df.iloc[:, :2].rename(columns={df.columns[0]: \"label\", df.columns[1]: \"text\"})\n",
    "\n",
    "    # Clean up label/text types\n",
    "    df[\"label\"] = df[\"label\"].astype(str).str.strip().str.lower()\n",
    "    df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "    # Filter to only expected labels\n",
    "    df = df[df[\"label\"].isin([\"ham\", \"spam\"])].reset_index(drop=True)\n",
    "    print(f\"[info] Dataset size: {len(df)} (ham={sum(df.label=='ham')}, spam={sum(df.label=='spam')})\")\n",
    "    return df\n",
    "\n",
    "# ---------------------\n",
    "# Text Cleaning / Tokenization\n",
    "# ---------------------\n",
    "RE_HTML = re.compile(r\"<.*?>\")\n",
    "RE_URL = re.compile(r\"(https?://\\S+|www\\.\\S+)\")\n",
    "RE_EMAIL = re.compile(r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\")\n",
    "RE_NUM = re.compile(r\"\\d+\")\n",
    "RE_PUNCT = re.compile(rf\"[{re.escape(string.punctuation)}]\")\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "LEMMATIZER = WordNetLemmatizer()\n",
    "\n",
    "def _wordnet_pos(treebank_tag):\n",
    "    \"\"\"\n",
    "    Map NLTK POS tags to WordNet POS tags for better lemmatization.\n",
    "    \"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return 'a'  # adjective\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return 'v'  # verb\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return 'n'  # noun\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return 'r'  # adverb\n",
    "    return 'n'  # default to noun\n",
    "\n",
    "def clean_for_eda(text, remove_emails_urls_html=True, lower=True, remove_numbers=True, remove_punct=True,\n",
    "                  remove_stop=True, lemma=False):\n",
    "    \"\"\"\n",
    "    Light cleaning used for EDA (top words/ngrams + wordcloud).\n",
    "    The prompt only mandates removing stopwords, but we also remove obvious noise (urls/emails/html/punct/numbers)\n",
    "    so counts/wordclouds are meaningful.\n",
    "    Lemmatization is optional (default False) for EDA.\n",
    "    Returns a list of tokens.\n",
    "    \"\"\"\n",
    "    if remove_emails_urls_html:\n",
    "        text = RE_HTML.sub(\" \", text)\n",
    "        text = RE_URL.sub(\" \", text)\n",
    "        text = RE_EMAIL.sub(\" \", text)\n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "    if remove_numbers:\n",
    "        text = RE_NUM.sub(\" \", text)\n",
    "    if remove_punct:\n",
    "        text = RE_PUNCT.sub(\" \", text)\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    if remove_stop:\n",
    "        tokens = [t for t in tokens if t not in STOPWORDS and t.strip()]\n",
    "\n",
    "    if lemma:\n",
    "        # POS-tag-based lemmatization\n",
    "        tagged = pos_tag(tokens)\n",
    "        tokens = [LEMMATIZER.lemmatize(w, _wordnet_pos(pos)) for w, pos in tagged]\n",
    "\n",
    "    return [t for t in tokens if t]\n",
    "\n",
    "\n",
    "def advanced_tokenizer(text):\n",
    "    \"\"\"\n",
    "    Full preprocessing pipeline for modeling step #5 (Tf-IDF + preprocessing).\n",
    "    Steps:\n",
    "      - tokenize the text\n",
    "      - convert to lower case\n",
    "      - remove stop words\n",
    "      - remove email-ids, urls and html tags if any\n",
    "      - remove numbers\n",
    "      - remove punctuation marks\n",
    "      - apply Lemmatization to each token\n",
    "    Returns a list of lemmas suitable for scikit-learn vectorizers (tokenizer usage).\n",
    "    \"\"\"\n",
    "    # Order: remove html/urls/emails first to avoid junk tokens\n",
    "    text = RE_HTML.sub(\" \", text)\n",
    "    text = RE_URL.sub(\" \", text)\n",
    "    text = RE_EMAIL.sub(\" \", text)\n",
    "    text = text.lower()\n",
    "    text = RE_NUM.sub(\" \", text)\n",
    "    text = RE_PUNCT.sub(\" \", text)\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in STOPWORDS and t.strip()]\n",
    "\n",
    "    tagged = pos_tag(tokens)\n",
    "    lemmas = [LEMMATIZER.lemmatize(w, _wordnet_pos(pos)) for w, pos in tagged]\n",
    "    return [t for t in lemmas if t]\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# EDA Helpers\n",
    "# ---------------------\n",
    "def get_top_ngrams(tokens_list, n=1, topk=10):\n",
    "    \"\"\"\n",
    "    Given a list of tokens, compute top-k n-grams.\n",
    "    \"\"\"\n",
    "    if n == 1:\n",
    "        grams = tokens_list\n",
    "    else:\n",
    "        grams = [\" \".join(tokens_list[i:i+n]) for i in range(len(tokens_list) - n + 1)]\n",
    "    counter = Counter(grams)\n",
    "    return counter.most_common(topk)\n",
    "\n",
    "def eda_by_class(df, label_value, topk=10, save_prefix=\"ham\"):\n",
    "    \"\"\"\n",
    "    Compute and save EDA artifacts for a given class.\n",
    "    - 10 most frequent unigrams, bigrams, trigrams (after cleaning; stopwords removed)\n",
    "    - Wordcloud image\n",
    "    Returns dict with DataFrames for the top n-grams.\n",
    "    \"\"\"\n",
    "    subset = df[df[\"label\"] == label_value][\"text\"].tolist()\n",
    "    # Build a flat list of tokens with EDA cleaning (no lemmatization by default)\n",
    "    tokens_all = []\n",
    "    for txt in subset:\n",
    "        tokens_all.extend(clean_for_eda(txt, lemma=False))\n",
    "\n",
    "    # Top n-grams\n",
    "    uni = get_top_ngrams(tokens_all, n=1, topk=topk)\n",
    "    bi = get_top_ngrams(tokens_all, n=2, topk=topk)\n",
    "    tri = get_top_ngrams(tokens_all, n=3, topk=topk)\n",
    "\n",
    "    uni_df = pd.DataFrame(uni, columns=[\"unigram\", \"count\"])\n",
    "    bi_df = pd.DataFrame(bi, columns=[\"bigram\", \"count\"])\n",
    "    tri_df = pd.DataFrame(tri, columns=[\"trigram\", \"count\"])\n",
    "\n",
    "    uni_df.to_csv(ARTIFACT_DIR / f\"top_{save_prefix}_unigrams.csv\", index=False)\n",
    "    bi_df.to_csv(ARTIFACT_DIR / f\"top_{save_prefix}_bigrams.csv\", index=False)\n",
    "    tri_df.to_csv(ARTIFACT_DIR / f\"top_{save_prefix}_trigrams.csv\", index=False)\n",
    "\n",
    "    # Wordcloud\n",
    "    try:\n",
    "        from wordcloud import WordCloud\n",
    "        wc_text = \" \".join(tokens_all)\n",
    "        if wc_text.strip():\n",
    "            wc = WordCloud(width=1200, height=600, background_color=\"white\").generate(wc_text)\n",
    "            plt.figure(figsize=(12,6))\n",
    "            plt.imshow(wc, interpolation=\"bilinear\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.tight_layout()\n",
    "            out_path = ARTIFACT_DIR / f\"wordcloud_{save_prefix}.png\"\n",
    "            plt.savefig(out_path, dpi=150)\n",
    "            plt.close()\n",
    "            print(f\"[info] Saved wordcloud: {out_path}\")\n",
    "        else:\n",
    "            print(f\"[warn] No tokens for wordcloud ({save_prefix}).\")\n",
    "    except Exception as e:\n",
    "        print(\"[warn] WordCloud failed:\", repr(e))\n",
    "\n",
    "    return {\"uni\": uni_df, \"bi\": bi_df, \"tri\": tri_df}\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# Modeling\n",
    "# ---------------------\n",
    "def evaluate_model(name, vectorizer, model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Fit vectorizer+model, evaluate on test, return macro-F1 and report path.\n",
    "    \"\"\"\n",
    "    Xtr = vectorizer.fit_transform(X_train)\n",
    "    Xte = vectorizer.transform(X_test)\n",
    "\n",
    "    model.fit(Xtr, y_train)\n",
    "    y_pred = model.predict(Xte)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"F1-macro: {f1:.4f}\")\n",
    "    print(\"Classification report:\")\n",
    "    report = classification_report(y_test, y_pred, digits=4)\n",
    "    print(report)\n",
    "\n",
    "    # Save report\n",
    "    report_path = ARTIFACT_DIR / f\"classification_report_{name.replace(' ', '_').lower()}.txt\"\n",
    "    with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{name}\\n\\nF1-macro: {f1:.6f}\\n\\n\")\n",
    "        f.write(report)\n",
    "    print(f\"[info] Saved report: {report_path}\")\n",
    "    return f1\n",
    "\n",
    "\n",
    "def main():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    print(\"[info] Loading dataset...\")\n",
    "    df = load_sms_spam()\n",
    "\n",
    "    # -----------------\n",
    "    # EDA\n",
    "    # -----------------\n",
    "    print(\"\\n[info] Running EDA...\")\n",
    "    ham_eda = eda_by_class(df, \"ham\", topk=TOPK, save_prefix=\"ham\")\n",
    "    spam_eda = eda_by_class(df, \"spam\", topk=TOPK, save_prefix=\"spam\")\n",
    "\n",
    "    # Save quick previews\n",
    "    ham_eda[\"uni\"].head(10).to_csv(ARTIFACT_DIR / \"preview_ham_unigrams.csv\", index=False)\n",
    "    spam_eda[\"uni\"].head(10).to_csv(ARTIFACT_DIR / \"preview_spam_unigrams.csv\", index=False)\n",
    "\n",
    "    # -----------------\n",
    "    # Train/Test Split\n",
    "    # -----------------\n",
    "    X = df[\"text\"].values\n",
    "    y = df[\"label\"].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    "    )\n",
    "    print(\"\\n[info] Data split:\")\n",
    "    print(\"  Train size:\", len(X_train), \" Test size:\", len(X_test))\n",
    "\n",
    "    # -----------------\n",
    "    # Modeling: same classifier for all experiments\n",
    "    # -----------------\n",
    "    clf = LogisticRegression(max_iter=1000, solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # 1) Bag-of-Words\n",
    "    bow_vec = CountVectorizer(stop_words=\"english\", min_df=2)\n",
    "    f1_bow = evaluate_model(\"BoW + LogisticRegression\", bow_vec, clf, X_train, X_test, y_train, y_test)\n",
    "    results.append((\"BoW\", f1_bow))\n",
    "\n",
    "    # 2) TF-IDF\n",
    "    tfidf_vec = TfidfVectorizer(stop_words=\"english\", min_df=2)\n",
    "    f1_tfidf = evaluate_model(\"TF-IDF + LogisticRegression\", tfidf_vec, clf, X_train, X_test, y_train, y_test)\n",
    "    results.append((\"TF-IDF\", f1_tfidf))\n",
    "\n",
    "    # 3) TF-IDF + Preprocessing (custom tokenizer does all cleaning steps incl. lemmatization)\n",
    "    tfidf_pre_vec = TfidfVectorizer(min_df=2, tokenizer=advanced_tokenizer, preprocessor=None, token_pattern=None)\n",
    "    f1_tfidf_pre = evaluate_model(\"TF-IDF+Preproc + LogisticRegression\", tfidf_pre_vec, clf, X_train, X_test, y_train, y_test)\n",
    "    results.append((\"TF-IDF + Preprocessing\", f1_tfidf_pre))\n",
    "\n",
    "    # -----------------\n",
    "    # Final Score Table\n",
    "    # -----------------\n",
    "    res_df = pd.DataFrame(results, columns=[\"Method\", \"F1_macro\"]).sort_values(\"F1_macro\", ascending=False)\n",
    "    print(\"\\n=== Final Scores (same classifier across methods) ===\")\n",
    "    print(res_df.to_string(index=False))\n",
    "\n",
    "    out_csv = ARTIFACT_DIR / \"final_scores.csv\"\n",
    "    res_df.to_csv(out_csv, index=False)\n",
    "    print(f\"[info] Saved final scores: {out_csv}\")\n",
    "\n",
    "    # Also save top n-gram CSV previews into a compact JSON for quick glance\n",
    "    summary = {\n",
    "        \"dataset_size\": len(df),\n",
    "        \"class_counts\": df[\"label\"].value_counts().to_dict(),\n",
    "        \"scores\": [{\"method\": m, \"f1_macro\": float(f)} for m, f in results],\n",
    "    }\n",
    "    with open(ARTIFACT_DIR / \"run_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"[info] Summary JSON saved at {ARTIFACT_DIR / 'run_summary.json'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
